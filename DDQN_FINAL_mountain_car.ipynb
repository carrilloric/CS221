{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DDQN_FINAL_mountain_car.ipynb","provenance":[],"authorship_tag":"ABX9TyMp/jHc0kulTD1I9Y8vDCG0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"XVSc5sjKA9ct","colab_type":"code","outputId":"3eec5395-11e6-4ca2-bef9-df3bfd48d7c6","executionInfo":{"status":"ok","timestamp":1591420410144,"user_tz":240,"elapsed":4003636,"user":{"displayName":"ricardo carrillo","photoUrl":"","userId":"05727590381692514706"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install gym\n","!pip install gym pyvirtualdisplay > /dev/null 2>&1\n","!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n","\n","\n","import random\n","import gym\n","import numpy as np\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from collections import deque\n","loss=[]\n","# Constants\n","c_env_name = 'MountainCar-v0'\n","\n","c_discount_rate = 0.99\n","c_learning_rate = 0.001\n","\n","c_memory_size = 20000\n","c_batch_size = 64\n","\n","# Required memory to start training\n","c_mem_len_train_start = 1000\n","\n","c_exploration_max = 1.0\n","c_exploration_min = 0.01\n","c_exploration_decay = 0.9995\n","\n","# Globals\n","g_state_size = None\n","g_action_size = None\n","\n","g_env = None\n","g_memory = deque(maxlen=c_memory_size)\n","\n","g_model = None\n","g_target_model = None\n","g_curriculum = None\n","\n","g_epsilon = c_exploration_max\n","\n","g_goal_pos = None\n","\n","\n","# General utils\n","def normalize(values, low, high):\n","    return (values - low) / (high - low)\n","\n","\n","# Reward methods\n","def compute_reward_state0(car_position):\n","    reward = 0\n","    if car_position >= g_goal_pos:\n","        reward = 10 ** 2\n","    elif car_position >= 0.9:\n","        reward = 10 ** (-1)\n","    elif car_position >= 0.8:\n","        reward = 10 ** (-2)\n","    elif car_position >= 0.7:\n","        reward = 10 ** (-3)\n","    elif car_position >= 0.6:\n","        reward = 10 ** (-4)\n","    elif car_position >= 0.5:\n","        reward = 10 ** (-6)\n","    elif car_position >= 0.4:\n","        reward = 10 ** (-7)\n","\n","    return reward\n","\n","\n","def compute_reward_state1(car_position):\n","    reward = -1\n","    if car_position >= g_goal_pos:\n","        reward = 10 ** 2\n","\n","    return reward\n","\n","\n","class TrainingCurriculum:\n","    max_nb_of_steps = [1500, 500, 200]\n","    nb_of_max_steps = len(max_nb_of_steps)\n","\n","    def __init__(self):\n","        self._reward_f = compute_reward_state0\n","        self._max_nb_of_steps_i = 0\n","        self._learning_state = 0\n","\n","    def compute_reward(self, car_position):\n","        return self._reward_f(car_position)\n","\n","    def get_max_nb_of_steps(self):\n","        return TrainingCurriculum.max_nb_of_steps[self._max_nb_of_steps_i]\n","\n","    def update_state(self, episodes_max_pos):\n","        global g_epsilon\n","\n","        if len(episodes_max_pos) <= 10:\n","            return\n","\n","        mean_pos_over_last_ten = float(np.mean(episodes_max_pos[-10:]))\n","        if mean_pos_over_last_ten >= g_goal_pos:\n","            episodes_max_pos.clear()\n","\n","            initial_learning_state = self._learning_state\n","            if self._learning_state == 0:\n","                self._learning_state = 1\n","                self._max_nb_of_steps_i = 1\n","\n","            elif self._learning_state == 1:\n","                self._learning_state = 2\n","                self._max_nb_of_steps_i = 2\n","\n","            elif self._learning_state == 2:\n","                self._learning_state = 3\n","                self._reward_f = compute_reward_state1\n","\n","            elif self._learning_state == 3:\n","                # Done training\n","                self._learning_state = -1\n","\n","            # If learning state has changed\n","            if initial_learning_state != self._learning_state:\n","                g_epsilon = max(g_epsilon, 0.3)\n","                print('Learning state has changed to ', self._learning_state)\n","\n","    def is_done_training(self):\n","        return self._learning_state == -1\n","\n","\n","# DQN\n","def build_model():\n","    model = Sequential()\n","\n","    model.add(Dense(24, activation='relu', input_dim=g_state_size, kernel_initializer='he_uniform'))\n","    model.add(Dense(24, activation='relu', kernel_initializer='he_uniform'))\n","    model.add(Dense(g_action_size, kernel_initializer='he_uniform'))\n","\n","    model.compile(Adam(lr=c_learning_rate), 'mse')\n","    return model\n","\n","\n","def update_target_model():\n","    g_target_model.set_weights(g_model.get_weights())\n","\n","\n","def get_action(state):\n","    if np.random.rand() < g_epsilon:\n","        return g_env.action_space.sample()\n","    else:\n","        q_values = g_model.predict(state)[0]\n","        return np.argmax(q_values)\n","\n","\n","def append_memory(state, action, reward, next_state, done):\n","    global g_epsilon\n","\n","    g_memory.append((state, action, reward, next_state, done))\n","\n","    if g_epsilon > c_exploration_min:\n","        g_epsilon = max(g_epsilon * c_exploration_decay, c_exploration_min)\n","\n","\n","def can_train():\n","    mem_len = len(g_memory)\n","    return mem_len >= c_mem_len_train_start and mem_len >= c_batch_size\n","\n","\n","def train_model():\n","    if not can_train():\n","        return\n","\n","    mini_batch = random.sample(g_memory, c_batch_size)\n","\n","    update_input = np.zeros((c_batch_size, g_state_size))\n","    update_target = np.zeros((c_batch_size, g_state_size))\n","    action, reward, done = [], [], []\n","\n","    for i in range(c_batch_size):\n","        update_input[i] = mini_batch[i][0]\n","        action.append(mini_batch[i][1])\n","        reward.append(mini_batch[i][2])\n","        update_target[i] = mini_batch[i][3]\n","        done.append(mini_batch[i][4])\n","\n","    target = g_model.predict(update_input)\n","    target_next = g_model.predict(update_target)\n","    target_val = g_target_model.predict(update_target)\n","\n","    for i in range(c_batch_size):\n","        if done[i]:\n","            target[i][action[i]] = reward[i]\n","        else:\n","            # The key point of Double DQN:\n","            #  Selection of action is from model\n","            #  Update is from target model\n","            a = np.argmax(target_next[i])\n","            target[i][action[i]] = reward[i] + c_discount_rate * target_val[i][a]\n","\n","    g_model.fit(\n","        update_input,\n","        target,\n","        batch_size=c_batch_size,\n","        epochs=1,\n","        verbose=0)\n","\n","\n","def reshape_state(state):\n","    return np.reshape(state, [1, g_state_size])\n","\n","\n","def normalize_state(state):\n","    return normalize(state, g_env.low, g_env.high)\n","\n","\n","def preprocess_state(state):\n","    state = reshape_state(state)\n","    state = normalize_state(state)\n","    return state\n","\n","\n","# noinspection PyShadowingNames\n","def run_episode():\n","    done = False\n","    score = 0.0\n","    state = preprocess_state(g_env.reset())\n","    episode_max_pos = -999\n","    step = 0\n","\n","    while not done:\n","        #g_env.render()\n","\n","        action = get_action(state)\n","        next_state, reward, done, info = g_env.step(action)\n","        next_state = preprocess_state(next_state)\n","\n","        # Normalized car position\n","        car_position = state[0][0]\n","\n","        done = (step >= g_curriculum.get_max_nb_of_steps()) or (car_position >= g_goal_pos)\n","\n","        if car_position > episode_max_pos:\n","            episode_max_pos = car_position\n","\n","        reward = g_curriculum.compute_reward(car_position)\n","\n","        append_memory(state, action, reward, next_state, done)\n","        train_model()\n","        score += reward\n","        state = next_state\n","        step += 1\n","\n","    return score, episode_max_pos, step\n","\n","\n","# Mountain car specific\n","def get_normalized_goal_position():\n","    state = g_env.observation_space.sample()\n","    state[0] = g_env.goal_position\n","    state = normalize_state(state)\n","    return state[0]\n","\n","\n","if __name__ == '__main__':\n","    g_env = gym.make(c_env_name)\n","    g_state_size = g_env.observation_space.shape[0]\n","    g_action_size = g_env.action_space.n\n","\n","    g_model = build_model()\n","    g_target_model = build_model()\n","    g_curriculum = TrainingCurriculum()\n","\n","    max_positions = []\n","\n","    g_goal_pos = get_normalized_goal_position()\n","\n","    for episode in range(200):\n","        update_target_model()\n","\n","        score, episode_max_pos, steps = run_episode()\n","        max_positions.append(episode_max_pos)\n","\n","        pos_mean = float(np.mean(max_positions[-min(10, len(max_positions)):]))\n","        print(\n","            \"episode: %3d, score: %03.4f, max_pos: %.2f, epsilon: %.4f, steps: %4d, pos_mean: %4.2f\" %\n","            (episode, score, episode_max_pos, g_epsilon, steps, pos_mean))\n","        g_curriculum.update_state(max_positions)\n","        loss.append(score)\n","\n","        #if g_curriculum.is_done_training():\n","            #g_model.save('trained_models/trained_v0.h5')\n","            #break"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n","episode:   0, score: 100.3784, max_pos: 0.95, epsilon: 0.5531, steps: 1184, pos_mean: 0.95\n","episode:   1, score: 100.7240, max_pos: 0.95, epsilon: 0.4032, steps:  632, pos_mean: 0.95\n","episode:   2, score: 1.8653, max_pos: 0.91, epsilon: 0.1903, steps: 1501, pos_mean: 0.94\n","episode:   3, score: 100.6523, max_pos: 0.96, epsilon: 0.1331, steps:  716, pos_mean: 0.94\n","episode:   4, score: 100.3105, max_pos: 0.95, epsilon: 0.1060, steps:  455, pos_mean: 0.94\n","episode:   5, score: 100.7529, max_pos: 0.94, epsilon: 0.0814, steps:  527, pos_mean: 0.94\n","episode:   6, score: 100.4936, max_pos: 0.95, epsilon: 0.0674, steps:  379, pos_mean: 0.95\n","episode:   7, score: 101.9424, max_pos: 0.95, epsilon: 0.0445, steps:  831, pos_mean: 0.95\n","episode:   8, score: 103.6080, max_pos: 0.95, epsilon: 0.0292, steps:  842, pos_mean: 0.95\n","episode:   9, score: 100.4744, max_pos: 0.95, epsilon: 0.0266, steps:  182, pos_mean: 0.95\n","episode:  10, score: 101.7132, max_pos: 0.95, epsilon: 0.0174, steps:  846, pos_mean: 0.95\n","Learning state has changed to  1\n","episode:  11, score: 100.4916, max_pos: 0.94, epsilon: 0.2541, steps:  332, pos_mean: 0.94\n","episode:  12, score: 101.0795, max_pos: 0.95, epsilon: 0.2027, steps:  452, pos_mean: 0.95\n","episode:  13, score: 0.3123, max_pos: 0.87, epsilon: 0.1578, steps:  501, pos_mean: 0.92\n","episode:  14, score: 0.1852, max_pos: 0.83, epsilon: 0.1228, steps:  501, pos_mean: 0.90\n","episode:  15, score: 0.3029, max_pos: 0.85, epsilon: 0.0956, steps:  501, pos_mean: 0.89\n","episode:  16, score: 0.0230, max_pos: 0.74, epsilon: 0.0744, steps:  501, pos_mean: 0.86\n","episode:  17, score: 0.0516, max_pos: 0.77, epsilon: 0.0579, steps:  501, pos_mean: 0.85\n","episode:  18, score: 0.0009, max_pos: 0.63, epsilon: 0.0451, steps:  501, pos_mean: 0.82\n","episode:  19, score: 0.0018, max_pos: 0.63, epsilon: 0.0351, steps:  501, pos_mean: 0.80\n","episode:  20, score: 0.0080, max_pos: 0.70, epsilon: 0.0273, steps:  501, pos_mean: 0.79\n","episode:  21, score: 0.0247, max_pos: 0.77, epsilon: 0.0213, steps:  501, pos_mean: 0.77\n","episode:  22, score: 101.7571, max_pos: 0.95, epsilon: 0.0168, steps:  467, pos_mean: 0.77\n","episode:  23, score: 0.0027, max_pos: 0.66, epsilon: 0.0131, steps:  501, pos_mean: 0.75\n","episode:  24, score: 0.2469, max_pos: 0.83, epsilon: 0.0102, steps:  501, pos_mean: 0.75\n","episode:  25, score: 0.4090, max_pos: 0.87, epsilon: 0.0100, steps:  501, pos_mean: 0.75\n","episode:  26, score: 0.0324, max_pos: 0.79, epsilon: 0.0100, steps:  501, pos_mean: 0.76\n","episode:  27, score: 100.6980, max_pos: 0.95, epsilon: 0.0100, steps:  469, pos_mean: 0.78\n","episode:  28, score: 100.2868, max_pos: 0.96, epsilon: 0.0100, steps:  397, pos_mean: 0.81\n","episode:  29, score: 100.4716, max_pos: 0.94, epsilon: 0.0100, steps:  416, pos_mean: 0.84\n","episode:  30, score: 0.4441, max_pos: 0.89, epsilon: 0.0100, steps:  501, pos_mean: 0.86\n","episode:  31, score: 0.0001, max_pos: 0.56, epsilon: 0.0100, steps:  501, pos_mean: 0.84\n","episode:  32, score: 0.0001, max_pos: 0.57, epsilon: 0.0100, steps:  501, pos_mean: 0.80\n","episode:  33, score: 0.0001, max_pos: 0.55, epsilon: 0.0100, steps:  501, pos_mean: 0.79\n","episode:  34, score: 0.0001, max_pos: 0.52, epsilon: 0.0100, steps:  501, pos_mean: 0.76\n","episode:  35, score: 0.0001, max_pos: 0.54, epsilon: 0.0100, steps:  501, pos_mean: 0.73\n","episode:  36, score: 0.0001, max_pos: 0.53, epsilon: 0.0100, steps:  501, pos_mean: 0.70\n","episode:  37, score: 0.0001, max_pos: 0.52, epsilon: 0.0100, steps:  501, pos_mean: 0.66\n","episode:  38, score: 0.0002, max_pos: 0.55, epsilon: 0.0100, steps:  501, pos_mean: 0.62\n","episode:  39, score: 0.0001, max_pos: 0.51, epsilon: 0.0100, steps:  501, pos_mean: 0.58\n","episode:  40, score: 100.5884, max_pos: 0.95, epsilon: 0.0100, steps:  495, pos_mean: 0.58\n","episode:  41, score: 0.2913, max_pos: 0.83, epsilon: 0.0100, steps:  501, pos_mean: 0.61\n","episode:  42, score: 0.0000, max_pos: 0.50, epsilon: 0.0100, steps:  501, pos_mean: 0.60\n","episode:  43, score: 0.0001, max_pos: 0.51, epsilon: 0.0100, steps:  501, pos_mean: 0.60\n","episode:  44, score: 0.0002, max_pos: 0.57, epsilon: 0.0100, steps:  501, pos_mean: 0.60\n","episode:  45, score: 0.0000, max_pos: 0.49, epsilon: 0.0100, steps:  501, pos_mean: 0.60\n","episode:  46, score: 0.0001, max_pos: 0.49, epsilon: 0.0100, steps:  501, pos_mean: 0.59\n","episode:  47, score: 0.0001, max_pos: 0.53, epsilon: 0.0100, steps:  501, pos_mean: 0.59\n","episode:  48, score: 0.0001, max_pos: 0.52, epsilon: 0.0100, steps:  501, pos_mean: 0.59\n","episode:  49, score: 0.0002, max_pos: 0.55, epsilon: 0.0100, steps:  501, pos_mean: 0.59\n","episode:  50, score: 0.0001, max_pos: 0.51, epsilon: 0.0100, steps:  501, pos_mean: 0.55\n","episode:  51, score: 0.0000, max_pos: 0.48, epsilon: 0.0100, steps:  501, pos_mean: 0.51\n","episode:  52, score: 101.0067, max_pos: 0.96, epsilon: 0.0100, steps:  222, pos_mean: 0.56\n","episode:  53, score: 0.3986, max_pos: 0.85, epsilon: 0.0100, steps:  501, pos_mean: 0.60\n","episode:  54, score: 0.0001, max_pos: 0.51, epsilon: 0.0100, steps:  501, pos_mean: 0.59\n","episode:  55, score: 0.0001, max_pos: 0.50, epsilon: 0.0100, steps:  501, pos_mean: 0.59\n","episode:  56, score: 100.7195, max_pos: 0.95, epsilon: 0.0100, steps:  430, pos_mean: 0.64\n","episode:  57, score: 100.8974, max_pos: 0.95, epsilon: 0.0100, steps:  223, pos_mean: 0.68\n","episode:  58, score: 0.0001, max_pos: 0.51, epsilon: 0.0100, steps:  501, pos_mean: 0.68\n","episode:  59, score: 100.5034, max_pos: 0.95, epsilon: 0.0100, steps:  204, pos_mean: 0.72\n","episode:  60, score: 100.6685, max_pos: 0.95, epsilon: 0.0100, steps:  209, pos_mean: 0.76\n","episode:  61, score: 100.5773, max_pos: 0.95, epsilon: 0.0100, steps:  260, pos_mean: 0.81\n","episode:  62, score: 100.7495, max_pos: 0.95, epsilon: 0.0100, steps:  235, pos_mean: 0.81\n","episode:  63, score: 100.6345, max_pos: 0.95, epsilon: 0.0100, steps:  211, pos_mean: 0.82\n","episode:  64, score: 100.5071, max_pos: 0.95, epsilon: 0.0100, steps:  187, pos_mean: 0.86\n","episode:  65, score: 100.7195, max_pos: 0.95, epsilon: 0.0100, steps:  207, pos_mean: 0.91\n","episode:  66, score: 100.5195, max_pos: 0.95, epsilon: 0.0100, steps:  197, pos_mean: 0.91\n","episode:  67, score: 100.6896, max_pos: 0.95, epsilon: 0.0100, steps:  259, pos_mean: 0.91\n","episode:  68, score: 100.6965, max_pos: 0.95, epsilon: 0.0100, steps:  157, pos_mean: 0.95\n","Learning state has changed to  2\n","episode:  69, score: 0.2770, max_pos: 0.86, epsilon: 0.2713, steps:  201, pos_mean: 0.86\n","episode:  70, score: 0.1541, max_pos: 0.81, epsilon: 0.2454, steps:  201, pos_mean: 0.84\n","episode:  71, score: 0.0012, max_pos: 0.63, epsilon: 0.2219, steps:  201, pos_mean: 0.77\n","episode:  72, score: 0.0761, max_pos: 0.80, epsilon: 0.2007, steps:  201, pos_mean: 0.78\n","episode:  73, score: 0.1901, max_pos: 0.82, epsilon: 0.1815, steps:  201, pos_mean: 0.79\n","episode:  74, score: 0.2749, max_pos: 0.86, epsilon: 0.1641, steps:  201, pos_mean: 0.80\n","episode:  75, score: 0.2860, max_pos: 0.85, epsilon: 0.1484, steps:  201, pos_mean: 0.80\n","episode:  76, score: 0.1600, max_pos: 0.82, epsilon: 0.1342, steps:  201, pos_mean: 0.81\n","episode:  77, score: 0.0231, max_pos: 0.80, epsilon: 0.1214, steps:  201, pos_mean: 0.80\n","episode:  78, score: 100.5754, max_pos: 0.95, epsilon: 0.1127, steps:  148, pos_mean: 0.82\n","episode:  79, score: 100.5882, max_pos: 0.94, epsilon: 0.1042, steps:  158, pos_mean: 0.83\n","episode:  80, score: 0.0535, max_pos: 0.80, epsilon: 0.0942, steps:  201, pos_mean: 0.83\n","episode:  81, score: 100.3666, max_pos: 0.96, epsilon: 0.0874, steps:  150, pos_mean: 0.86\n","episode:  82, score: 100.4740, max_pos: 0.95, epsilon: 0.0808, steps:  157, pos_mean: 0.87\n","episode:  83, score: 0.2240, max_pos: 0.85, epsilon: 0.0731, steps:  201, pos_mean: 0.88\n","episode:  84, score: 100.3654, max_pos: 0.95, epsilon: 0.0678, steps:  150, pos_mean: 0.89\n","episode:  85, score: 100.3653, max_pos: 0.95, epsilon: 0.0631, steps:  143, pos_mean: 0.90\n","episode:  86, score: 0.0904, max_pos: 0.81, epsilon: 0.0571, steps:  201, pos_mean: 0.90\n","episode:  87, score: 100.3659, max_pos: 0.95, epsilon: 0.0530, steps:  150, pos_mean: 0.91\n","episode:  88, score: 100.3568, max_pos: 0.96, epsilon: 0.0491, steps:  150, pos_mean: 0.91\n","episode:  89, score: 0.0344, max_pos: 0.82, epsilon: 0.0444, steps:  201, pos_mean: 0.90\n","episode:  90, score: 0.3625, max_pos: 0.90, epsilon: 0.0402, steps:  201, pos_mean: 0.91\n","episode:  91, score: 100.2653, max_pos: 0.95, epsilon: 0.0374, steps:  144, pos_mean: 0.91\n","episode:  92, score: 100.2806, max_pos: 0.95, epsilon: 0.0339, steps:  198, pos_mean: 0.91\n","episode:  93, score: 0.0662, max_pos: 0.89, epsilon: 0.0306, steps:  201, pos_mean: 0.91\n","episode:  94, score: 100.3847, max_pos: 0.95, epsilon: 0.0284, steps:  149, pos_mean: 0.91\n","episode:  95, score: 0.3620, max_pos: 0.89, epsilon: 0.0257, steps:  201, pos_mean: 0.90\n","episode:  96, score: 100.5305, max_pos: 0.95, epsilon: 0.0236, steps:  174, pos_mean: 0.92\n","episode:  97, score: 100.8064, max_pos: 0.95, epsilon: 0.0219, steps:  148, pos_mean: 0.92\n","episode:  98, score: 0.3051, max_pos: 0.85, epsilon: 0.0198, steps:  201, pos_mean: 0.91\n","episode:  99, score: 100.4656, max_pos: 0.96, epsilon: 0.0184, steps:  148, pos_mean: 0.92\n","episode: 100, score: 100.2656, max_pos: 0.95, epsilon: 0.0170, steps:  157, pos_mean: 0.93\n","episode: 101, score: 100.2662, max_pos: 0.95, epsilon: 0.0158, steps:  144, pos_mean: 0.93\n","episode: 102, score: 100.2651, max_pos: 0.94, epsilon: 0.0147, steps:  144, pos_mean: 0.93\n","episode: 103, score: 0.0146, max_pos: 0.74, epsilon: 0.0133, steps:  201, pos_mean: 0.91\n","episode: 104, score: 100.3629, max_pos: 0.95, epsilon: 0.0122, steps:  170, pos_mean: 0.91\n","episode: 105, score: 100.3644, max_pos: 0.96, epsilon: 0.0113, steps:  165, pos_mean: 0.92\n","episode: 106, score: 100.3563, max_pos: 0.96, epsilon: 0.0104, steps:  160, pos_mean: 0.92\n","episode: 107, score: 0.0273, max_pos: 0.84, epsilon: 0.0100, steps:  201, pos_mean: 0.91\n","episode: 108, score: 0.0289, max_pos: 0.82, epsilon: 0.0100, steps:  201, pos_mean: 0.91\n","episode: 109, score: 100.3744, max_pos: 0.95, epsilon: 0.0100, steps:  146, pos_mean: 0.90\n","episode: 110, score: 100.2652, max_pos: 0.95, epsilon: 0.0100, steps:  142, pos_mean: 0.90\n","episode: 111, score: 100.3572, max_pos: 0.95, epsilon: 0.0100, steps:  181, pos_mean: 0.90\n","episode: 112, score: 0.0012, max_pos: 0.63, epsilon: 0.0100, steps:  201, pos_mean: 0.87\n","episode: 113, score: 100.3698, max_pos: 0.95, epsilon: 0.0100, steps:  166, pos_mean: 0.89\n","episode: 114, score: 100.3797, max_pos: 0.95, epsilon: 0.0100, steps:  199, pos_mean: 0.89\n","episode: 115, score: 100.3677, max_pos: 0.95, epsilon: 0.0100, steps:  160, pos_mean: 0.89\n","episode: 116, score: 0.0011, max_pos: 0.63, epsilon: 0.0100, steps:  201, pos_mean: 0.86\n","episode: 117, score: 100.2661, max_pos: 0.95, epsilon: 0.0100, steps:  159, pos_mean: 0.87\n","episode: 118, score: 0.4395, max_pos: 0.89, epsilon: 0.0100, steps:  201, pos_mean: 0.88\n","episode: 119, score: 100.8054, max_pos: 0.95, epsilon: 0.0100, steps:  155, pos_mean: 0.88\n","episode: 120, score: 100.5373, max_pos: 0.95, epsilon: 0.0100, steps:  170, pos_mean: 0.88\n","episode: 121, score: 100.2685, max_pos: 0.95, epsilon: 0.0100, steps:  168, pos_mean: 0.88\n","episode: 122, score: 0.0008, max_pos: 0.61, epsilon: 0.0100, steps:  201, pos_mean: 0.88\n","episode: 123, score: 100.3553, max_pos: 0.96, epsilon: 0.0100, steps:  144, pos_mean: 0.88\n","episode: 124, score: 0.0000, max_pos: 0.39, epsilon: 0.0100, steps:  201, pos_mean: 0.82\n","episode: 125, score: 100.3653, max_pos: 0.95, epsilon: 0.0100, steps:  158, pos_mean: 0.82\n","episode: 126, score: 100.3550, max_pos: 0.95, epsilon: 0.0100, steps:  152, pos_mean: 0.85\n","episode: 127, score: 0.0076, max_pos: 0.71, epsilon: 0.0100, steps:  201, pos_mean: 0.83\n","episode: 128, score: 100.2785, max_pos: 0.95, epsilon: 0.0100, steps:  155, pos_mean: 0.83\n","episode: 129, score: 0.0000, max_pos: 0.37, epsilon: 0.0100, steps:  201, pos_mean: 0.78\n","episode: 130, score: 0.0000, max_pos: 0.37, epsilon: 0.0100, steps:  201, pos_mean: 0.72\n","episode: 131, score: 0.0166, max_pos: 0.77, epsilon: 0.0100, steps:  201, pos_mean: 0.70\n","episode: 132, score: 100.3836, max_pos: 0.95, epsilon: 0.0100, steps:  166, pos_mean: 0.74\n","episode: 133, score: 100.3806, max_pos: 0.95, epsilon: 0.0100, steps:  159, pos_mean: 0.73\n","episode: 134, score: 0.3315, max_pos: 0.89, epsilon: 0.0100, steps:  201, pos_mean: 0.78\n","episode: 135, score: 0.0000, max_pos: 0.46, epsilon: 0.0100, steps:  201, pos_mean: 0.74\n","episode: 136, score: 100.3816, max_pos: 0.95, epsilon: 0.0100, steps:  159, pos_mean: 0.74\n","episode: 137, score: 100.3816, max_pos: 0.95, epsilon: 0.0100, steps:  171, pos_mean: 0.76\n","episode: 138, score: 102.4483, max_pos: 0.95, epsilon: 0.0100, steps:  196, pos_mean: 0.76\n","episode: 139, score: 100.2808, max_pos: 0.95, epsilon: 0.0100, steps:  166, pos_mean: 0.82\n","episode: 140, score: 100.8584, max_pos: 0.95, epsilon: 0.0100, steps:  201, pos_mean: 0.88\n","episode: 141, score: 100.2916, max_pos: 0.95, epsilon: 0.0100, steps:  186, pos_mean: 0.89\n","episode: 142, score: 0.3053, max_pos: 0.88, epsilon: 0.0100, steps:  201, pos_mean: 0.89\n","episode: 143, score: 100.4754, max_pos: 0.95, epsilon: 0.0100, steps:  159, pos_mean: 0.89\n","episode: 144, score: 2.5584, max_pos: 0.92, epsilon: 0.0100, steps:  201, pos_mean: 0.89\n","episode: 145, score: 101.3175, max_pos: 0.95, epsilon: 0.0100, steps:   97, pos_mean: 0.94\n","episode: 146, score: 0.3970, max_pos: 0.86, epsilon: 0.0100, steps:  201, pos_mean: 0.93\n","episode: 147, score: 101.4982, max_pos: 0.96, epsilon: 0.0100, steps:  185, pos_mean: 0.93\n","episode: 148, score: 100.3725, max_pos: 0.96, epsilon: 0.0100, steps:  199, pos_mean: 0.93\n","episode: 149, score: 100.5854, max_pos: 0.95, epsilon: 0.0100, steps:  163, pos_mean: 0.93\n","episode: 150, score: 100.4603, max_pos: 0.95, epsilon: 0.0100, steps:  167, pos_mean: 0.93\n","episode: 151, score: 100.2774, max_pos: 0.95, epsilon: 0.0100, steps:  153, pos_mean: 0.93\n","episode: 152, score: 0.3925, max_pos: 0.88, epsilon: 0.0100, steps:  201, pos_mean: 0.93\n","episode: 153, score: 100.8014, max_pos: 0.96, epsilon: 0.0100, steps:  197, pos_mean: 0.93\n","episode: 154, score: 100.2547, max_pos: 0.96, epsilon: 0.0100, steps:  147, pos_mean: 0.94\n","episode: 155, score: 100.6282, max_pos: 0.96, epsilon: 0.0100, steps:  178, pos_mean: 0.94\n","episode: 156, score: 100.2566, max_pos: 0.96, epsilon: 0.0100, steps:  155, pos_mean: 0.95\n","Learning state has changed to  3\n","episode: 157, score: -79.0000, max_pos: 0.94, epsilon: 0.2742, steps:  180, pos_mean: 0.94\n","episode: 158, score: -62.0000, max_pos: 0.95, epsilon: 0.2527, steps:  163, pos_mean: 0.95\n","episode: 159, score: -201.0000, max_pos: 0.63, epsilon: 0.2285, steps:  201, pos_mean: 0.84\n","episode: 160, score: -201.0000, max_pos: 0.76, epsilon: 0.2067, steps:  201, pos_mean: 0.82\n","episode: 161, score: -74.0000, max_pos: 0.94, epsilon: 0.1894, steps:  175, pos_mean: 0.85\n","episode: 162, score: -201.0000, max_pos: 0.92, epsilon: 0.1713, steps:  201, pos_mean: 0.86\n","episode: 163, score: -51.0000, max_pos: 0.95, epsilon: 0.1587, steps:  152, pos_mean: 0.87\n","episode: 164, score: -62.0000, max_pos: 0.94, epsilon: 0.1463, steps:  163, pos_mean: 0.88\n","episode: 165, score: -201.0000, max_pos: 0.76, epsilon: 0.1323, steps:  201, pos_mean: 0.87\n","episode: 166, score: -201.0000, max_pos: 0.63, epsilon: 0.1196, steps:  201, pos_mean: 0.84\n","episode: 167, score: -57.0000, max_pos: 0.95, epsilon: 0.1106, steps:  158, pos_mean: 0.84\n","episode: 168, score: -59.0000, max_pos: 0.95, epsilon: 0.1021, steps:  160, pos_mean: 0.85\n","episode: 169, score: -201.0000, max_pos: 0.89, epsilon: 0.0923, steps:  201, pos_mean: 0.87\n","episode: 170, score: -58.0000, max_pos: 0.95, epsilon: 0.0852, steps:  159, pos_mean: 0.89\n","episode: 171, score: -201.0000, max_pos: 0.68, epsilon: 0.0771, steps:  201, pos_mean: 0.86\n","episode: 172, score: -56.0000, max_pos: 0.96, epsilon: 0.0713, steps:  157, pos_mean: 0.87\n","episode: 173, score: -201.0000, max_pos: 0.91, epsilon: 0.0645, steps:  201, pos_mean: 0.86\n","episode: 174, score: -201.0000, max_pos: 0.59, epsilon: 0.0583, steps:  201, pos_mean: 0.83\n","episode: 175, score: -65.0000, max_pos: 0.95, epsilon: 0.0536, steps:  166, pos_mean: 0.85\n","episode: 176, score: -57.0000, max_pos: 0.95, epsilon: 0.0496, steps:  158, pos_mean: 0.88\n","episode: 177, score: -201.0000, max_pos: 0.85, epsilon: 0.0448, steps:  201, pos_mean: 0.87\n","episode: 178, score: -79.0000, max_pos: 0.95, epsilon: 0.0410, steps:  180, pos_mean: 0.87\n","episode: 179, score: -54.0000, max_pos: 0.95, epsilon: 0.0379, steps:  155, pos_mean: 0.87\n","episode: 180, score: -44.0000, max_pos: 0.96, epsilon: 0.0353, steps:  145, pos_mean: 0.87\n","episode: 181, score: -99.0000, max_pos: 0.95, epsilon: 0.0319, steps:  200, pos_mean: 0.90\n","episode: 182, score: -34.0000, max_pos: 0.95, epsilon: 0.0298, steps:  135, pos_mean: 0.90\n","episode: 183, score: -201.0000, max_pos: 0.61, epsilon: 0.0270, steps:  201, pos_mean: 0.87\n","episode: 184, score: -51.0000, max_pos: 0.95, epsilon: 0.0250, steps:  152, pos_mean: 0.91\n","episode: 185, score: -55.0000, max_pos: 0.95, epsilon: 0.0231, steps:  156, pos_mean: 0.91\n","episode: 186, score: -25.0000, max_pos: 0.95, epsilon: 0.0217, steps:  126, pos_mean: 0.91\n","episode: 187, score: -55.0000, max_pos: 0.95, epsilon: 0.0201, steps:  156, pos_mean: 0.92\n","episode: 188, score: -63.0000, max_pos: 0.96, epsilon: 0.0185, steps:  164, pos_mean: 0.92\n","episode: 189, score: -49.0000, max_pos: 0.96, epsilon: 0.0172, steps:  150, pos_mean: 0.92\n","episode: 190, score: -49.0000, max_pos: 0.95, epsilon: 0.0159, steps:  150, pos_mean: 0.92\n","episode: 191, score: -43.0000, max_pos: 0.96, epsilon: 0.0148, steps:  144, pos_mean: 0.92\n","episode: 192, score: -63.0000, max_pos: 0.95, epsilon: 0.0136, steps:  164, pos_mean: 0.92\n","episode: 193, score: -53.0000, max_pos: 0.95, epsilon: 0.0126, steps:  154, pos_mean: 0.95\n","Learning state has changed to  -1\n","episode: 194, score: -201.0000, max_pos: 0.84, epsilon: 0.2713, steps:  201, pos_mean: 0.84\n","episode: 195, score: -201.0000, max_pos: 0.87, epsilon: 0.2454, steps:  201, pos_mean: 0.86\n","episode: 196, score: -201.0000, max_pos: 0.73, epsilon: 0.2219, steps:  201, pos_mean: 0.82\n","episode: 197, score: -41.0000, max_pos: 0.95, epsilon: 0.2067, steps:  142, pos_mean: 0.85\n","episode: 198, score: -201.0000, max_pos: 0.86, epsilon: 0.1869, steps:  201, pos_mean: 0.85\n","episode: 199, score: -24.0000, max_pos: 0.94, epsilon: 0.1756, steps:  125, pos_mean: 0.87\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yrboVNOUHNci","colab_type":"code","outputId":"e9fad2a1-830e-47f5-ac83-f30664e86e27","executionInfo":{"status":"error","timestamp":1591432864366,"user_tz":240,"elapsed":1998,"user":{"displayName":"ricardo carrillo","photoUrl":"","userId":"05727590381692514706"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","# %matplotlib inline\n","print(loss)\n","plt.plot([i+1 for i in range(0,200,1)], loss[:])\n","plt.xlabel('Episode no.')\n","plt.ylabel('Score')\n","plt.show()"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-89cf2651f828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# %matplotlib inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Episode no.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"]}]}]}